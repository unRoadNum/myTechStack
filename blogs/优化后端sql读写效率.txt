# 优化后端sql读写效率

# 背景
***
   最近要给设备增加某数据的批量功能，包括导入导出和删除。具体的背景是这样的：
1. 大概数据记录的规格是500左右，后端的数据库类型是sqlite3。
2. Cgi跟后端数据管理模块中间有一个适配模块，这个适配模块最大允许转发数据容量大概
有60条上述记录左右。

# 初期设计
***
刚开始设计的时候，跟前端讨论了以后，出了一个简单的方案。
1. 前端分包将数据下发到数据管理模块，每个包最大可携带记录数是50条，这样500条数据导入到
后端需要分10次。
2. 前端的输入数据是通过网管ftp从csv文件中读出来的，将数据的规格校验放在了前端做，
每条记录的合法性放在后端校验。
3. 导入数据的方式采用覆盖的方式，具体的方案是前端先发送一个删除全部记录的消息，然后开始
发送分包批量导入消息。

# 实际操作
***
我和一个前端做这个功能，很快搞定了，在内部编译服务器上调试没有任何问题，除了导入的时候略
长以外（ps：大概就1分钟左右，这个我后来复现观察了下，时间上下浮动不超过10秒）。对一个10个
包左右的导入来说，我认为这个时间还是可以接受的。就没有在意，到了上了设备做最后联调，要提测
的时候。导入的时候发现单板的cpu利用率卡在了99%，居高不下，而且导致页面卡死，惊出了我一身的冷汗。
明明以前调试的时候并没有这种情况啊，虽然时间会长点，但也不会这样啊，此时我大慌。
打印了一下调用栈，没有死循环，只是发现业务线程频繁读写数据库。又检查了一下我的代码，发现
了问题。
我在后台读写数据库的方案是对于每次的50条记录，逐条去校验记录的合法性，然后将校验过的当前记录insert
进表。单板的cpu被频繁的数据库连接占用，导致了页面的卡死。

# 优化方案
***
我的想法是将数据库连接提取出来，在数据全部导入以后，然后再close。程序封装sqlite3的模块，
没有相关的函数，只需要增加相关函数即可。在我的数据管理模块，调用新增加的sqlite3的接口函数
就可以完成性能的提升。编译调试以后，发现确实没有以前的卡页面的现象了。
心中窃喜，终于解决这个问题了。

# 递进
***
做完了上述的优化以后，我想着既然已经新增了封装的接口函数，好人做到底，直接把每次批量导入做成
事务处理，这样似乎更加符合批量处理的逻辑。

# 补充
***
批量导出，也相应的修改成了事务处理。将表中的记录，读出写到和前端约定的url中。

